tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, generator=test_datagen, batch_size = batch_size)
########################
# VGG16 transfer learning
set.seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3),
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
freeze_weights(vgg16_partial, from = 1, to = 6)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 10,
epochs = 20
)
library(keras)
cifar10 <- dataset_cifar10()
trn_x <- cifar10$train$x[1:5000, , , ]
trn_y <- to_categorical(cifar10$train$y[1:5000])
batch_size <- 64
n__trn_samples <- nrow(trn_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range = 20,
width_shift_range = 0.2,
height_shift_range = 0.2,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = TRUE,
fill_mode = 'nearest')
train_generator <- flow_images_from_data(
trn_x, generator=datagen, batch_size = batch_size
)
tst_x <- cifar10$test$x[1:500, , , ]
tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, generator=test_datagen, batch_size = batch_size)
########################
# VGG16 transfer learning
set.seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3),
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
freeze_weights(vgg16_partial, from = 1, to = 6)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 10,
epochs = 20
)
library(keras)
cifar10 <- dataset_cifar10()
trn_x <- cifar10$train$x[1:5000, , , ]
trn_y <- to_categorical(cifar10$train$y[1:5000])
batch_size <- 64
n__trn_samples <- nrow(trn_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range = 20,
width_shift_range = 0.2,
height_shift_range = 0.2,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = TRUE,
fill_mode = 'nearest')
train_generator <- flow_images_from_data(
trn_x, generator=datagen, batch_size = batch_size
)
tst_x <- cifar10$test$x[1:500, , , ]
tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, generator=test_datagen, batch_size = batch_size)
########################
# VGG16 transfer learning
set.seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3),
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
freeze_weights(vgg16_partial, from = 1, to = 6)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 10,
epochs = 20
)
?fit_image_data_generator
library(keras)
cifar10 <- dataset_cifar10()
trn_x <- cifar10$train$x[1:5000, , , ]/255
trn_y <- to_categorical(cifar10$train$y[1:5000])/255
batch_size <- 64
n__trn_samples <- nrow(trn_x)
datagen <- image_data_generator(rotation_range = 20,
width_shift_range = 0.2,
height_shift_range = 0.2,
horizontal_flip = TRUE)
train_generator <- flow_images_from_data(
trn_x, trn_y, generator=datagen, batch_size = batch_size
)
tst_x <- cifar10$test$x[1:500, , , ]
tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
library(keras)
cifar10 <- dataset_cifar10()
trn_x <- cifar10$train$x[1:5000, , , ]
trn_y <- to_categorical(cifar10$train$y[1:5000])
batch_size <- 64
n__trn_samples <- nrow(trn_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range = 20,
width_shift_range = 0.2,
height_shift_range = 0.2,
horizontal_flip = TRUE)
train_generator <- flow_images_from_data(
trn_x, trn_y, generator=datagen, batch_size = batch_size
)
tst_x <- cifar10$test$x[1:500, , , ]
tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, tst_y, generator=test_datagen, batch_size = batch_size)
########################
# VGG16 transfer learning
set.seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3),
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
freeze_weights(vgg16_partial, from = 1, to = 6)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 10,
epochs = 20
)
library(keras)
trn_x <- cifar10$train$x[1:5000, , , ]
trn_y <- to_categorical(cifar10$train$y[1:5000])
batch_size <- 64
n__trn_samples <- nrow(trn_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range = 20,
width_shift_range = 0.2,
height_shift_range = 0.2,
horizontal_flip = TRUE)
train_generator <- flow_images_from_data(
trn_x, trn_y, generator=datagen, batch_size = batch_size
)
tst_x <- cifar10$test$x[1:500, , , ]
tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, tst_y, generator=test_datagen, batch_size = batch_size)
########################
# VGG16 transfer learning
set.seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3),
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
freeze_weights(vgg16_partial, from = 1, to = 6)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = as.integer(n_samples/batch_size),
epochs = 20,
validation_data = test_generator,
validation_steps = as.integer(n_tst_samples/batch_size)
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = as.integer(n__trn_samples/batch_size),
epochs = 20,
validation_data = test_generator,
validation_steps = as.integer(n_tst_samples/batch_size)
)
datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_data(
trn_x, trn_y, generator=datagen, batch_size = batch_size
)
tst_x <- cifar10$test$x[1:500, , , ]
tst_y <- to_categorical(cifar10$test$y[1:500])
n_tst_samples = nrow(tst_x)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, tst_y, generator=test_datagen, batch_size = batch_size)
########################
# VGG16 transfer learning
set.seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3),
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
freeze_weights(vgg16_partial, from = 1, to = 6)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = as.integer(n__trn_samples/batch_size),
epochs = 20,
validation_data = test_generator,
validation_steps = as.integer(n_tst_samples/batch_size)
)
model %>% fit(trn_x, trn_y, epochs=20, batch_size=64)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(trn_x, trn_y, epochs=20, batch_size=64)
library(keras)
cifar10 <- dataset_cifar10()
#trn_x <- cifar10$train$x[1:5000, , , ]/255
#trn_y <- to_categorical(cifar10$train$y[1:5000])
trn_x <- cifar10$train$x
trn_y <- to_categorical(cifar10$train$y)
#tst_x <- cifar10$test$x[1:500, , , ]/255
#tst_y <- to_categorical(cifar10$test$y[1:500])
tst_x <- cifar10$test$x
tst_y <- to_categorical(cifar10$test$y)
########################
# VGG16 transfer learning
# fine tuning up to VGG16 block 3
set.seed(578)
tensorflow::tf$random$set_seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3)
)
library(keras)
cifar10 <- dataset_cifar10()
#trn_x <- cifar10$train$x[1:5000, , , ]/255
#trn_y <- to_categorical(cifar10$train$y[1:5000])
trn_x <- cifar10$train$x
trn_y <- to_categorical(cifar10$train$y)
#tst_x <- cifar10$test$x[1:500, , , ]/255
#tst_y <- to_categorical(cifar10$test$y[1:500])
tst_x <- cifar10$test$x
tst_y <- to_categorical(cifar10$test$y)
batch_size <- 64
n_trn_samples <- nrow(trn_x)
n_tst_samples <- nrow(tst_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range=20,
width_shift_range = 0.2,
height_shift_range = 0.2,
horizontal_flip = TRUE )
train_generator <- flow_images_from_data(
trn_x, trn_y, generator = datagen, batch_size = batch_size)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, tst_y, generator = test_datagen, batch_size = batch_size)
set.seed(578)
tensorflow::tf$random$set_seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3)
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 196, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit_generator(
train_generator, steps_per_epoch = as.integer(n_trn_samples/batch_size),
epochs = 20,
validation_data = test_generator,
validation_steps = as.integer(n_tst_samples/batch_size)
)
library(keras)
cifar10 <- dataset_cifar10()
#trn_x <- cifar10$train$x[1:5000, , , ]/255
#trn_y <- to_categorical(cifar10$train$y[1:5000])
trn_x <- cifar10$train$x
trn_y <- to_categorical(cifar10$train$y)
#tst_x <- cifar10$test$x[1:500, , , ]/255
#tst_y <- to_categorical(cifar10$test$y[1:500])
tst_x <- cifar10$test$x
tst_y <- to_categorical(cifar10$test$y)
batch_size <- 64
n_trn_samples <- nrow(trn_x)
n_tst_samples <- nrow(tst_x)
batch_size <- 64
n_trn_samples <- nrow(trn_x)
n_tst_samples <- nrow(tst_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range=20,
width_shift_range = 0.2,
height_shift_range = 0.2,
horizontal_flip = TRUE )
train_generator <- flow_images_from_data(
trn_x, trn_y, generator = datagen, batch_size = batch_size)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, tst_y, generator = test_datagen, batch_size = batch_size)
set.seed(578)
tensorflow::tf$random$set_seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3)
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 196, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit_generator(
train_generator, steps_per_epoch = as.integer(n_trn_samples/batch_size),
epochs = 20,
validation_data = test_generator,
validation_steps = as.integer(n_tst_samples/batch_size)
)
install_keras()
library(keras)
cifar10 <- dataset_cifar10()
#trn_x <- cifar10$train$x[1:5000, , , ]/255
#trn_y <- to_categorical(cifar10$train$y[1:5000])
trn_x <- cifar10$train$x
trn_y <- to_categorical(cifar10$train$y)
#tst_x <- cifar10$test$x[1:500, , , ]/255
#tst_y <- to_categorical(cifar10$test$y[1:500])
tst_x <- cifar10$test$x
tst_y <- to_categorical(cifar10$test$y)
batch_size <- 64
n_trn_samples <- nrow(trn_x)
n_tst_samples <- nrow(tst_x)
datagen <- image_data_generator(rescale = 1/255,
rotation_range=20,
width_shift_range = 0.2,
height_shift_range = 0.2,
horizontal_flip = TRUE )
train_generator <- flow_images_from_data(
trn_x, trn_y, generator = datagen, batch_size = batch_size)
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_data(
tst_x, tst_y, generator = test_datagen, batch_size = batch_size)
set.seed(578)
tensorflow::tf$random$set_seed(578)
vgg16_base <- application_vgg16(
weights = 'imagenet',
include_top = FALSE,
input_shape = c(32,32,3)
)
vgg16_partial <- keras_model(inputs = vgg16_base$input,
outputs = get_layer(vgg16_base, 'block3_pool')$output)
model <- keras_model_sequential() %>%
vgg16_partial %>%
layer_flatten() %>%
layer_dense(units = 196, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit_generator(
train_generator, steps_per_epoch = as.integer(n_trn_samples/batch_size),
epochs = 20,
validation_data = test_generator,
validation_steps = as.integer(n_tst_samples/batch_size)
)
source('~/Gdrive/CSU/STAA578/HW5/DataPrep.R')
d = data.frame(cores = c(1,2,4,6,8),)
d = data.frame(cores = c(1,2,4,6,8),time=c(2.686,4.366,8.741,15.398))
d = data.frame(cores = c(1,2,4,6,8),time=c(2.686,3.115,4.366,8.741,15.398))
plot(d)
d = data.frame(cores = c(1,2,4,6,8),time=rev(c(2.686,3.115,4.366,8.741,15.398)))
plot(d)
plot(d, type='b', pch=19)
plot(d$cores, log10(d$time), type='b', pch=19)
cores = c(1:4)
time = c(19.929, 10.122, 6.897, 5.860)
plot(cores, time, pch=19, type='n')
plot(cores, time, pch=19, type='b')
cores = c(1:8)
time = c(19.924, 10.181, 6.902, 6.372, 5.762,6.105,5.699,4.546)
plot(cores, time, pch=19, type='b')
cores = c(1:20)
time = c(19.924, 10.181, 6.902, 6.372, 5.762,6.105,5.699,4.546)
time = c(19.924, 10.181, 6.902, 6.372,
5.762,  6.105, 5.699, 4.546,
5.137,  4.387, 4.351, 4.026,
4.301,  4.152, 3.873, 4.398,
4.895,  4.520, 3.863, 4.432)
plot(cores, time, pch=19, type='b')
cores = c(1,4,8,16,20)
time = c(78.331, 21.186, 13.566, 10,280, 9.509, 9.190)
plot(cores, time, pch=19, type='b')
cores = c(1,4,8,12,16,20)
plot(cores, time, pch=19, type='b')
cores = c(1,4,8,12,16,20)
time = c(78.331, 21.186, 13.566, 10,280, 9.509, 9.190)
plot(cores, time, pch=19, type='b')
length(cores)
length(time)
time = c(78.331, 21.186, 13.566, 10.280, 9.509, 9.190)
plot(cores, time, pch=19, type='b')
setwd("~/Projects/Jigsaw")
c(-10:-1),0,c(1:10)
c(-10:-1),0,c(1:10))
c(-10:-1)
c(c(-10:-1),0,c(1:10))
-10:10
