{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "from PuzzlePiece import *\n",
    "from SWPuzzleAligner import *\n",
    "from NWPuzzleAligner import *\n",
    "from EuclideanSimilarity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all the pieces\n",
    "target_pieces = {}\n",
    "\n",
    "for p in ['NW','SW']: #['C','N','NE','E','SE','S','SW','W','NW']:\n",
    "    target_pieces[p] = PuzzlePiece('3x3_pieces/' + p + '_border.csv', \n",
    "                                   border_sampling_rate = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first piece\n",
    "query = target_pieces.pop('NW') # this piece serves as the core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SW'])\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# REPEAT HERE\n",
    "##############################\n",
    "print(target_pieces.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7329979851588926\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9070e4d09e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m                           list(q_fine_seq.keys())[slip+slip-s:len(q_fine_seq)-s]}\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mfine_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEucSim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputeSubseqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_slip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_fine_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_dist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfine_dist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/JigSolve/general_design/EuclideanSimilarity.py\u001b[0m in \u001b[0;36mComputeSubseqDist\u001b[0;34m(self, M, N)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# in the passed sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         xshift = int((sum([M[p]['x'] for p in M]) - \\\n\u001b[0m\u001b[1;32m     66\u001b[0m                       sum([N[p]['x'] for p in N])) / len(M))\n\u001b[1;32m     67\u001b[0m         yshift = int((sum([M[p]['y'] for p in M]) - \\\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# find the closest match in the other pieces\n",
    "EucSim = EuclideanSimilarity()\n",
    "SWAligner = SWPuzzleAligner(EucSim)\n",
    "NWAligner = NWPuzzleAligner(EucSim)\n",
    "\n",
    "mx_score = 0\n",
    "mx_piece = ''\n",
    "\n",
    "all_align = {}\n",
    "rough_piece_align = {}\n",
    "fine_piece_align = {}\n",
    "\n",
    "rough_alignments_count = 1\n",
    "\n",
    "min_rough_score = None\n",
    "min_rough_piece = None\n",
    "    \n",
    "for i,p in enumerate(target_pieces):\n",
    "    \n",
    "    target = target_pieces[p]\n",
    "    \n",
    "    # extend the query to account for circular sequence\n",
    "    tail_length = min(int(len(target_pieces[p].border_sample) * .25),\n",
    "                      int(len(query.border_sample) * .25))\n",
    "\n",
    "    query.extend_border_sample(tail_length)\n",
    "    target.extend_border_sample(tail_length, reverse = True)\n",
    "    \n",
    "    # do a rough alignment with the extended border sample\n",
    "    rough_piece_align = SWAligner.Align(Q = query.border_sample_ext, \n",
    "                                        T = target.border_sample_ext,\n",
    "                                        window = 5, cutoff_percentile = 0.05,\n",
    "                                        return_top = rough_alignments_count) \n",
    "    \n",
    "    if max(rough_piece_align['mx']) > mx_score:\n",
    "        mx_score = max(rough_piece_align['mx'])\n",
    "        mx_piece = p\n",
    "    \n",
    "    all_align[p] = rough_piece_align\n",
    "    all_align[p]['fine_dist'] = {}\n",
    "    \n",
    "    # for each rough alignent, do a fine alignment\n",
    "    for i in range(rough_alignments_count):\n",
    "        \n",
    "        ####################\n",
    "        # find start and stop matched points for the fine alignment\n",
    "        \n",
    "        q_stop = query.ext_to_old_index[rough_piece_align['mx_Q'][i]] + 1\n",
    "        q_start = q_stop - rough_piece_align['length'][i] - 2\n",
    "        \n",
    "        if q_start < 0:\n",
    "            q_start += len(query.border_sample)\n",
    "        elif q_start >= len(query.border_sample):\n",
    "            q_start -= len(query.border_sample)\n",
    "            \n",
    "        q_orig_start = query.border_sample[q_start]['orig_idx']\n",
    "        q_orig_stop = query.border_sample[q_stop]['orig_idx']\n",
    "        \n",
    "        if q_orig_start < q_orig_stop:\n",
    "            q_fine_seq = {i:query.ordered_border[b] \n",
    "                          for i,b in enumerate(range(q_orig_start, q_orig_stop,))}\n",
    "        else:\n",
    "            idx = [i for i in range(q_orig_start,len(query.ordered_border))]\n",
    "            idx = idx + [i for i in range(0, q_orig_stop+1)]\n",
    "            q_fine_seq = {i:query.ordered_border[b] for i,b in enumerate(idx)}\n",
    "            \n",
    "        t_start = target.ext_to_old_index[rough_piece_align['mx_T'][i]]\n",
    "        t_stop = t_start + rough_piece_align['length'][i]\n",
    "        \n",
    "        if t_stop >= len(target.border_sample):\n",
    "            t_stop -= len(target.border_sample)\n",
    "            \n",
    "        t_orig_start = target.border_sample[t_start]['orig_idx']\n",
    "        t_orig_stop = target.border_sample[t_stop]['orig_idx']\n",
    "        \n",
    "        if t_orig_start < t_orig_stop:\n",
    "            t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(range(t_orig_stop, t_orig_start, -1))}\n",
    "        else:\n",
    "            idx = [i for i in range(t_orig_stop,-1,-1)]\n",
    "            idx = idx + [i for i in range(len(target.ordered_border)-1, t_orig_start-1, -1)]\n",
    "            t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(idx)}\n",
    "        \n",
    "        min_dist = None\n",
    "        slip = query.border_sample[1]['orig_idx'] - query.border_sample[0]['orig_idx']\n",
    "        all_align[p]['fine_dist'][p+str(i)] = {}\n",
    "        for s in range(2 * slip + 1):\n",
    "            if s < slip:\n",
    "                q_slip = { k:q_fine_seq[k] for k in \n",
    "                          list(q_fine_seq.keys())[slip+slip-s:len(q_fine_seq)-s] }\n",
    "            elif s == slip:\n",
    "                q_slip = { k:q_fine_seq[k] for k in \n",
    "                          list(q_fine_seq.keys())[slip:len(q_fine_seq)-slip] }\n",
    "            else:\n",
    "                q_slip = { k:q_fine_seq[k] for k in \n",
    "                          list(q_fine_seq.keys())[slip+slip-s:len(q_fine_seq)-s]}\n",
    "            \n",
    "            fine_dist = EucSim.ComputeSubseqDist(q_slip, t_fine_seq)\n",
    "            if min_dist is None or fine_dist < min_dist:\n",
    "                min_dist = fine_dist\n",
    "                min_slip = s\n",
    "                \n",
    "            if min_rough_score is None or min_dist < min_rough_score:\n",
    "                min_rough_score = min_dist\n",
    "                min_rough_piece = p\n",
    "                min_rough_align = i\n",
    "            \n",
    "        all_align[p]['fine_dist'][p+str(i)]['fine_dist'] = min_dist\n",
    "        all_align[p]['fine_dist'][p+str(i)]['fine_slip'] = min_slip\n",
    "        all_align['best_piece'] = min_rough_piece\n",
    "        all_align['best_align'] = min_rough_align\n",
    "            \n",
    "print(min_rough_piece, min_rough_align, min_rough_score)            \n",
    "#target = target_pieces.pop(mx_piece)['rough']\n",
    "target = target_pieces[min_rough_piece]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_piece = all_align['best_piece']\n",
    "mx_align = all_align['best_align']\n",
    "mx_piece_align = mx_piece+str(mx_align)\n",
    "\n",
    "#plot the current rough alignment\n",
    "mx = all_align[mx_piece]['mx'][mx_align]\n",
    "mx_Q = all_align[mx_piece]['mx_Q'][mx_align]\n",
    "mx_T = all_align[mx_piece]['mx_T'][mx_align]\n",
    "length = all_align[mx_piece]['length'][mx_align]\n",
    "min_slip = all_align[mx_piece]['fine_dist'][mx_piece_align]['fine_slip']\n",
    "\n",
    "# find the aligned points window\n",
    "Q_pt = query.border_sample[query.ext_to_old_index[mx_Q]]\n",
    "T_pt = target.border_sample[target.ext_to_old_index[mx_T]] \n",
    "\n",
    "# find x,y shift to align pieces based on that one point\n",
    "T_xshift = T_pt['x'] - Q_pt['x']\n",
    "T_yshift = T_pt['y'] - Q_pt['y'] \n",
    "\n",
    "plt.figure(figsize = [10,10])\n",
    "plt.scatter( [query.border_sample[k]['x'] for k,v in query.border_sample.items() ],\n",
    "             [query.border_sample[k]['y'] for k,v in query.border_sample.items() ])\n",
    "plt.scatter( [target.border_sample[k]['x'] - T_xshift for k,v in target.border_sample.items() ],\n",
    "             [target.border_sample[k]['y'] - T_yshift for k,v in target.border_sample.items() ])\n",
    "\n",
    "# show best matched points - second will overplot first due to alignment\n",
    "plt.scatter( Q_pt['x'], Q_pt['y'], s=400)\n",
    "plt.scatter( T_pt['x'] - T_xshift, T_pt['y'] - T_yshift, s=196 ) \n",
    "\n",
    "# show similarity window\n",
    "# the black and grey points represent the points in the positive scoring diagonal\n",
    "# of the suffix table starting at the maximum scoring point\n",
    "# these points are the best locally aligned points\n",
    "Q_window = [query.border_sample[query.ext_to_old_index[q]] for q in range(mx_Q - length, mx_Q)]\n",
    "plt.scatter( [p['x'] for p in Q_window],\n",
    "             [p['y'] for p in Q_window], c = 'grey' )\n",
    "\n",
    "T_window = [target.border_sample[target.ext_to_old_index[t]] for t in range(mx_T - length, mx_T)]\n",
    "plt.scatter( [p['x'] - T_xshift for p in T_window],\n",
    "             [p['y'] - T_yshift for p in T_window], c = 'black' )\n",
    "plt.show()\n",
    "\n",
    "# find the fine aligned points window\n",
    "q_stop = query.ext_to_old_index[mx_Q] + 1\n",
    "q_start = q_stop - length - 2\n",
    "\n",
    "if q_start < 0:\n",
    "    q_start += len(query.border_sample)\n",
    "elif q_start >= len(query.border_sample):\n",
    "    q_start -= len(query.border_sample)\n",
    "\n",
    "q_orig_start = query.border_sample[q_start]['orig_idx']\n",
    "q_orig_stop = query.border_sample[q_stop]['orig_idx']\n",
    "\n",
    "if q_orig_start < q_orig_stop:\n",
    "    q_fine_seq = {i:query.ordered_border[b] \n",
    "                  for i,b in enumerate(range(q_orig_start, q_orig_stop,))}\n",
    "else:\n",
    "    idx = [i for i in range(q_orig_start,len(query.ordered_border))]\n",
    "    idx = idx + [i for i in range(0, q_orig_stop+1)]\n",
    "    q_fine_seq = {i:query.ordered_border[b] for i,b in enumerate(idx)}\n",
    "\n",
    "t_start = target.ext_to_old_index[mx_T]\n",
    "t_stop = t_start + length\n",
    "\n",
    "if t_stop >= len(target.border_sample):\n",
    "    t_stop -= len(target.border_sample)\n",
    "\n",
    "t_orig_start = target.border_sample[t_start]['orig_idx']\n",
    "t_orig_stop = target.border_sample[t_stop]['orig_idx']\n",
    "\n",
    "Q_pt_fine = query.ordered_border[q_orig_stop - min_slip]\n",
    "T_pt_fine = target.ordered_border[t_orig_start]\n",
    "\n",
    " # find x,y shift to align pieces based on that one point\n",
    "T_xshift = T_pt_fine['x'] - Q_pt_fine['x']\n",
    "T_yshift = T_pt_fine['y'] - Q_pt_fine['y'] \n",
    "\n",
    "plt.figure(figsize = [10,10])\n",
    "plt.scatter( [query.ordered_border[k]['x'] for k,v in query.ordered_border.items() ],\n",
    "             [query.ordered_border[k]['y'] for k,v in query.ordered_border.items() ])\n",
    "plt.scatter( [target.ordered_border[k]['x'] - T_xshift for k,v in target.ordered_border.items() ],\n",
    "             [target.ordered_border[k]['y'] - T_yshift for k,v in target.ordered_border.items() ])\n",
    "\n",
    "# show best matched points - second will overplot first due to alignment\n",
    "plt.scatter( Q_pt_fine['x'], Q_pt_fine['y'], s=400)\n",
    "plt.scatter( T_pt_fine['x'] - T_xshift, T_pt_fine['y'] - T_yshift, s=196 ) \n",
    "\n",
    "print(len(q_fine_seq), len(t_fine_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = target.ext_to_old_index[mx_T]\n",
    "t_stop = t_start + length\n",
    "\n",
    "if t_stop >= len(target.border_sample):\n",
    "    t_stop -= len(target.border_sample)\n",
    "\n",
    "t_orig_start = target.border_sample[t_start]['orig_idx']\n",
    "t_orig_stop = target.border_sample[t_stop]['orig_idx']\n",
    "\n",
    "if t_orig_start < t_orig_stop:\n",
    "    t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(range(t_orig_stop, t_orig_start, -1))}\n",
    "else:\n",
    "    idx = [i for i in range(t_orig_stop,-1,-1)]\n",
    "    idx = idx + [i for i in range(len(target.ordered_border)-1, t_orig_start-1, -1)]\n",
    "    t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(idx)}\n",
    "    \n",
    "q_stop = query.ext_to_old_index[mx_Q] + 1\n",
    "q_start = q_stop - length - 2\n",
    "\n",
    "if q_start < 0:\n",
    "    q_start += len(query.border_sample)\n",
    "elif q_start >= len(query.border_sample):\n",
    "    q_start -= len(query.border_sample)\n",
    "\n",
    "q_orig_stop = query.border_sample[q_stop]['orig_idx'] - min_slip\n",
    "q_orig_start = q_orig_stop - len(t_fine_seq)\n",
    "\n",
    "if q_orig_start < q_orig_stop:\n",
    "    q_fine_seq = {i:query.ordered_border[b] \n",
    "                  for i,b in enumerate(range(q_orig_start, q_orig_stop,))}\n",
    "else:\n",
    "    idx = [i for i in range(q_orig_start,len(query.ordered_border))]\n",
    "    idx = idx + [i for i in range(0, q_orig_stop+1)]\n",
    "    q_fine_seq = {i:query.ordered_border[b] for i,b in enumerate(idx)}\n",
    "\n",
    "target.reposition_by_border(t_fine_seq, q_fine_seq)   \n",
    "    \n",
    "    \n",
    "Q_x = [ q[1]['x'] for q in query.ordered_border.items() ]\n",
    "Q_y = [ q[1]['y'] for q in query.ordered_border.items() ]\n",
    "\n",
    "T_orig_x = [ t[1]['x'] for t in target.border.items() ]\n",
    "T_orig_y = [ t[1]['y'] for t in target.border.items() ]\n",
    "\n",
    "T_shifted_x = [t[1]['x'] for t in target.border.items() ]\n",
    "T_shifted_y = [t[1]['y'] for t in target.border.items() ]\n",
    "\n",
    "plt.figure(figsize = [15,15])\n",
    "plt.scatter( Q_x, Q_y, c = 'blue', s=16)\n",
    "plt.scatter( T_orig_x, T_orig_y, c = 'orange', s=16)\n",
    "plt.scatter( T_shifted_x, T_shifted_y, c = 'black', s=16)\n",
    "            \n",
    "query.merge(target)\n",
    "\n",
    "Q_merged_x = [ q[1]['x'] for q in query.border.items() ]\n",
    "Q_merged_y = [ q[1]['y'] for q in query.border.items() ]\n",
    "\n",
    "plt.figure(figsize = [15,15])\n",
    "plt.scatter( Q_merged_x, Q_merged_y, c = 'blue', s=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# REPEAT ABOVE\n",
    "######################### \n",
    "\n",
    "# burn this one for now\n",
    "target = target_pieces.pop(mx_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
