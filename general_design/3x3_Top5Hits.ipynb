{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "from PuzzlePiece import *\n",
    "from SWPuzzleAligner import *\n",
    "from NWPuzzleAligner import *\n",
    "from EuclideanSimilarity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all the pieces\n",
    "target_pieces = {}\n",
    "\n",
    "for p in ['C','N','S','NE','E','SE','S','SW','W','NW']:\n",
    "    target_pieces[p] = PuzzlePiece('3x3_pieces/' + p + '_border.csv', \n",
    "                                   border_sampling_rate = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first piece\n",
    "query = target_pieces.pop('W') # this piece serves as the core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C', 'N', 'S', 'NE', 'E', 'SE', 'SW', 'NW'])\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# REPEAT HERE\n",
    "##############################\n",
    "print(target_pieces.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [222, 212, 202, 192, 182, 172, 165, 164, 169, 173, 169, 159, 149, 139, 129, 121, 122, 128, 130, 127, 117, 107, 97]\n",
      "Y:  [70, 71, 72, 71, 69, 64, 55, 45, 35, 25, 15, 9, 7, 8, 11, 20, 30, 40, 50, 60, 67, 70, 71]\n",
      "C {'mx': [23], 'mx_Q': [44], 'mx_T': [37], 'length': [24]}\n",
      "X:  [59, 60, 59, 58, 53, 43, 33, 25, 17, 12, 10, 10, 10, 13, 20, 30, 40, 49, 55, 57, 58]\n",
      "Y:  [22, 32, 42, 52, 62, 68, 66, 58, 65, 75, 83, 93, 103, 113, 121, 116, 110, 117, 127, 137, 147]\n",
      "N {'mx': [21], 'mx_Q': [68], 'mx_T': [109], 'length': [22]}\n",
      "X:  [74, 78, 80, 81, 78, 70, 60, 50, 40, 30, 20, 12, 8, 7, 8, 14, 24, 34, 44, 54, 64, 74, 81]\n",
      "Y:  [36, 46, 56, 66, 76, 85, 89, 89, 85, 82, 85, 92, 102, 104, 114, 124, 129, 128, 126, 123, 124, 129, 138]\n",
      "S {'mx': [19], 'mx_Q': [70], 'mx_T': [111], 'length': [24]}\n",
      "X:  [9, 8, 8, 9, 13, 22, 32, 42, 52, 62, 70, 72, 71, 67, 58]\n",
      "Y:  [32, 36, 46, 56, 66, 74, 75, 73, 71, 74, 83, 93, 103, 113, 121]\n",
      "NE {'mx': [15], 'mx_Q': [59], 'mx_T': [94], 'length': [16]}\n",
      "X:  [187, 177, 167, 157, 147, 138, 133, 133, 135, 137, 135, 127, 117, 107, 97, 93, 92, 92, 92, 92, 89, 79, 69]\n",
      "Y:  [70, 75, 79, 81, 80, 74, 64, 54, 44, 34, 24, 14, 7, 5, 8, 18, 28, 38, 48, 58, 68, 75, 76]\n",
      "E {'mx': [23], 'mx_Q': [44], 'mx_T': [49], 'length': [24]}\n",
      "X:  [234, 224, 214, 204, 194, 184, 177, 178, 181, 184, 183, 173, 163, 153, 143, 133, 133, 138, 140, 135, 125, 115, 105]\n",
      "Y:  [66, 68, 69, 70, 68, 63, 54, 44, 34, 24, 14, 8, 7, 9, 14, 23, 33, 43, 53, 63, 69, 71, 72]\n",
      "SE {'mx': [23], 'mx_Q': [44], 'mx_T': [38], 'length': [24]}\n",
      "X:  [176, 166, 156, 146, 136, 126, 116, 113, 121, 122, 112, 102, 92, 82, 72, 62, 67, 74, 69, 59, 49]\n",
      "Y:  [55, 56, 57, 57, 55, 52, 46, 36, 26, 16, 11, 7, 5, 4, 7, 14, 24, 34, 44, 51, 54]\n",
      "SW {'mx': [21], 'mx_Q': [43], 'mx_T': [26], 'length': [22]}\n",
      "X:  [11, 21, 31, 41, 51, 61, 66, 64, 61, 61, 70, 80, 90, 100, 110, 114, 112, 109, 112, 120, 130, 140, 150, 160]\n",
      "Y:  [189, 186, 185, 185, 187, 192, 202, 212, 222, 232, 241, 244, 246, 246, 242, 233, 223, 213, 203, 194, 190, 188, 187, 187]\n",
      "NW {'mx': [24], 'mx_Q': [96], 'mx_T': [71], 'length': [25]}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "97",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3939a07372a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mq_orig_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_start\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mq_orig_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq_orig_start\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mq_orig_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 97"
     ]
    }
   ],
   "source": [
    "# find the closest match in the other pieces\n",
    "EucSim = EuclideanSimilarity()\n",
    "SWAligner = SWPuzzleAligner(EucSim)\n",
    "NWAligner = NWPuzzleAligner(EucSim)\n",
    "\n",
    "mx_score = 0\n",
    "mx_piece = ''\n",
    "\n",
    "all_align = {}\n",
    "rough_piece_align = {}\n",
    "fine_piece_align = {}\n",
    "\n",
    "rough_alignments_count = 1\n",
    "\n",
    "min_rough_score = None\n",
    "min_rough_piece = None\n",
    "    \n",
    "for i,p in enumerate(target_pieces):\n",
    "    \n",
    "    target = target_pieces[p]\n",
    "    \n",
    "    # extend the query to account for circular sequence\n",
    "    tail_length = min(int(len(target_pieces[p].border_sample) * .25),\n",
    "                      int(len(query.border_sample) * .25))\n",
    "\n",
    "    query.extend_border_sample(tail_length)\n",
    "    target.extend_border_sample(tail_length, reverse = True)\n",
    "    \n",
    "    # do a rough alignment with the extended border sample\n",
    "    rough_piece_align = SWAligner.Align(Q = query.border_sample_ext, \n",
    "                                        T = target.border_sample_ext,\n",
    "                                        window = 5, cutoff_percentile = 0.05,\n",
    "                                        return_top = rough_alignments_count) \n",
    "    \n",
    "    print(p, rough_piece_align)\n",
    "    \n",
    "    if max(rough_piece_align['mx']) > mx_score:\n",
    "        mx_score = max(rough_piece_align['mx'])\n",
    "        mx_piece = p\n",
    "    \n",
    "    all_align[p] = rough_piece_align\n",
    "    all_align[p]['fine_dist'] = {}\n",
    "    \n",
    "    # for each rough alignent, do a fine alignment\n",
    "    for i in range(rough_alignments_count):\n",
    "        \n",
    "        ####################\n",
    "        # find start and stop matched points for the fine alignment\n",
    "        \n",
    "        q_stop = query.ext_to_old_index[rough_piece_align['mx_Q'][i]] + 1\n",
    "        q_start = q_stop - rough_piece_align['length'][i] - 2\n",
    "        \n",
    "        if q_start < 0:\n",
    "            q_start += len(query.border_sample)\n",
    "        elif q_start >= len(query.border_sample):\n",
    "            q_start -= len(query.border_sample)\n",
    "            \n",
    "        q_orig_start = query.border_sample[q_start]['orig_idx']\n",
    "        q_orig_stop = query.border_sample[q_stop]['orig_idx']\n",
    "        \n",
    "        if q_orig_start < q_orig_stop:\n",
    "            q_fine_seq = {i:query.ordered_border[b] \n",
    "                          for i,b in enumerate(range(q_orig_start, q_orig_stop,))}\n",
    "        else:\n",
    "            idx = [i for i in range(q_orig_start,len(query.ordered_border))]\n",
    "            idx = idx + [i for i in range(0, q_orig_stop+1)]\n",
    "            q_fine_seq = {i:query.ordered_border[b] for i,b in enumerate(idx)}\n",
    "            \n",
    "        t_start = target.ext_to_old_index[rough_piece_align['mx_T'][i]]\n",
    "        t_stop = t_start + rough_piece_align['length'][i]\n",
    "        \n",
    "        if t_stop >= len(target.border_sample):\n",
    "            t_stop -= len(target.border_sample)\n",
    "            \n",
    "        t_orig_start = target.border_sample[t_start]['orig_idx']\n",
    "        t_orig_stop = target.border_sample[t_stop]['orig_idx']\n",
    "        \n",
    "        if t_orig_start < t_orig_stop:\n",
    "            t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(range(t_orig_stop, t_orig_start, -1))}\n",
    "        else:\n",
    "            idx = [i for i in range(t_orig_stop,-1,-1)]\n",
    "            idx = idx + [i for i in range(len(target.ordered_border)-1, t_orig_start-1, -1)]\n",
    "            t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(idx)}\n",
    "        \n",
    "        min_dist = None\n",
    "        slip = query.border_sample[1]['orig_idx'] - query.border_sample[0]['orig_idx']\n",
    "        all_align[p]['fine_dist'][p+str(i)] = {}\n",
    "        for s in range(2 * slip + 1):\n",
    "            if s < slip:\n",
    "                q_slip = { k:q_fine_seq[k] for k in \n",
    "                          list(q_fine_seq.keys())[slip+slip-s:len(q_fine_seq)-s] }\n",
    "            elif s == slip:\n",
    "                q_slip = { k:q_fine_seq[k] for k in \n",
    "                          list(q_fine_seq.keys())[slip:len(q_fine_seq)-slip] }\n",
    "            else:\n",
    "                q_slip = { k:q_fine_seq[k] for k in \n",
    "                          list(q_fine_seq.keys())[slip+slip-s:len(q_fine_seq)-s]}\n",
    "            \n",
    "            fine_dist = EucSim.ComputeSubseqDist(q_slip, t_fine_seq)\n",
    "            if min_dist is None or fine_dist < min_dist:\n",
    "                min_dist = fine_dist\n",
    "                min_slip = s\n",
    "                \n",
    "            if min_rough_score is None or min_dist < min_rough_score:\n",
    "                min_rough_score = min_dist\n",
    "                min_rough_piece = p\n",
    "                min_rough_align = i\n",
    "            \n",
    "        all_align[p]['fine_dist'][p+str(i)]['fine_dist'] = min_dist\n",
    "        all_align[p]['fine_dist'][p+str(i)]['fine_slip'] = min_slip\n",
    "        all_align['best_piece'] = min_rough_piece\n",
    "        all_align['best_align'] = min_rough_align\n",
    "            \n",
    "print(min_rough_piece, min_rough_align, min_rough_score)            \n",
    "#target = target_pieces.pop(mx_piece)['rough']\n",
    "target = target_pieces[min_rough_piece]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_piece = all_align['best_piece']\n",
    "mx_align = all_align['best_align']\n",
    "mx_piece_align = mx_piece+str(mx_align)\n",
    "\n",
    "#plot the current rough alignment\n",
    "mx = all_align[mx_piece]['mx'][mx_align]\n",
    "mx_Q = all_align[mx_piece]['mx_Q'][mx_align]\n",
    "mx_T = all_align[mx_piece]['mx_T'][mx_align]\n",
    "length = all_align[mx_piece]['length'][mx_align]\n",
    "min_slip = all_align[mx_piece]['fine_dist'][mx_piece_align]['fine_slip']\n",
    "\n",
    "# find the aligned points window\n",
    "Q_pt = query.border_sample[query.ext_to_old_index[mx_Q]]\n",
    "T_pt = target.border_sample[target.ext_to_old_index[mx_T]] \n",
    "\n",
    "# find x,y shift to align pieces based on that one point\n",
    "T_xshift = T_pt['x'] - Q_pt['x']\n",
    "T_yshift = T_pt['y'] - Q_pt['y'] \n",
    "\n",
    "plt.figure(figsize = [10,10])\n",
    "plt.scatter( [query.border_sample[k]['x'] for k,v in query.border_sample.items() ],\n",
    "             [query.border_sample[k]['y'] for k,v in query.border_sample.items() ])\n",
    "plt.scatter( [target.border_sample[k]['x'] - T_xshift for k,v in target.border_sample.items() ],\n",
    "             [target.border_sample[k]['y'] - T_yshift for k,v in target.border_sample.items() ])\n",
    "\n",
    "# show best matched points - second will overplot first due to alignment\n",
    "plt.scatter( Q_pt['x'], Q_pt['y'], s=400)\n",
    "plt.scatter( T_pt['x'] - T_xshift, T_pt['y'] - T_yshift, s=196 ) \n",
    "\n",
    "# show similarity window\n",
    "# the black and grey points represent the points in the positive scoring diagonal\n",
    "# of the suffix table starting at the maximum scoring point\n",
    "# these points are the best locally aligned points\n",
    "Q_window = [query.border_sample[query.ext_to_old_index[q]] for q in range(mx_Q - length, mx_Q)]\n",
    "plt.scatter( [p['x'] for p in Q_window],\n",
    "             [p['y'] for p in Q_window], c = 'grey' )\n",
    "\n",
    "T_window = [target.border_sample[target.ext_to_old_index[t]] for t in range(mx_T - length, mx_T)]\n",
    "plt.scatter( [p['x'] - T_xshift for p in T_window],\n",
    "             [p['y'] - T_yshift for p in T_window], c = 'black' )\n",
    "plt.show()\n",
    "\n",
    "# find the fine aligned points window\n",
    "q_stop = query.ext_to_old_index[mx_Q] + 1\n",
    "q_start = q_stop - length - 2\n",
    "\n",
    "if q_start < 0:\n",
    "    q_start += len(query.border_sample)\n",
    "elif q_start >= len(query.border_sample):\n",
    "    q_start -= len(query.border_sample)\n",
    "\n",
    "q_orig_start = query.border_sample[q_start]['orig_idx']\n",
    "q_orig_stop = query.border_sample[q_stop]['orig_idx']\n",
    "\n",
    "if q_orig_start < q_orig_stop:\n",
    "    q_fine_seq = {i:query.ordered_border[b] \n",
    "                  for i,b in enumerate(range(q_orig_start, q_orig_stop,))}\n",
    "else:\n",
    "    idx = [i for i in range(q_orig_start,len(query.ordered_border))]\n",
    "    idx = idx + [i for i in range(0, q_orig_stop+1)]\n",
    "    q_fine_seq = {i:query.ordered_border[b] for i,b in enumerate(idx)}\n",
    "\n",
    "t_start = target.ext_to_old_index[mx_T]\n",
    "t_stop = t_start + length\n",
    "\n",
    "if t_stop >= len(target.border_sample):\n",
    "    t_stop -= len(target.border_sample)\n",
    "\n",
    "t_orig_start = target.border_sample[t_start]['orig_idx']\n",
    "t_orig_stop = target.border_sample[t_stop]['orig_idx']\n",
    "\n",
    "Q_pt_fine = query.ordered_border[q_orig_stop - min_slip]\n",
    "T_pt_fine = target.ordered_border[t_orig_start]\n",
    "\n",
    " # find x,y shift to align pieces based on that one point\n",
    "T_xshift = T_pt_fine['x'] - Q_pt_fine['x']\n",
    "T_yshift = T_pt_fine['y'] - Q_pt_fine['y'] \n",
    "\n",
    "plt.figure(figsize = [10,10])\n",
    "plt.scatter( [query.ordered_border[k]['x'] for k,v in query.ordered_border.items() ],\n",
    "             [query.ordered_border[k]['y'] for k,v in query.ordered_border.items() ])\n",
    "plt.scatter( [target.ordered_border[k]['x'] - T_xshift for k,v in target.ordered_border.items() ],\n",
    "             [target.ordered_border[k]['y'] - T_yshift for k,v in target.ordered_border.items() ])\n",
    "\n",
    "# show best matched points - second will overplot first due to alignment\n",
    "plt.scatter( Q_pt_fine['x'], Q_pt_fine['y'], s=400)\n",
    "plt.scatter( T_pt_fine['x'] - T_xshift, T_pt_fine['y'] - T_yshift, s=196 ) \n",
    "\n",
    "print(len(q_fine_seq), len(t_fine_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = target.ext_to_old_index[mx_T]\n",
    "t_stop = t_start + length\n",
    "\n",
    "if t_stop >= len(target.border_sample):\n",
    "    t_stop -= len(target.border_sample)\n",
    "\n",
    "t_orig_start = target.border_sample[t_start]['orig_idx']\n",
    "t_orig_stop = target.border_sample[t_stop]['orig_idx']\n",
    "\n",
    "if t_orig_start < t_orig_stop:\n",
    "    t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(range(t_orig_stop, t_orig_start, -1))}\n",
    "else:\n",
    "    idx = [i for i in range(t_orig_stop,-1,-1)]\n",
    "    idx = idx + [i for i in range(len(target.ordered_border)-1, t_orig_start-1, -1)]\n",
    "    t_fine_seq = {i:target.ordered_border[b] for i,b in enumerate(idx)}\n",
    "    \n",
    "q_stop = query.ext_to_old_index[mx_Q] + 1\n",
    "q_start = q_stop - length - 2\n",
    "\n",
    "if q_start < 0:\n",
    "    q_start += len(query.border_sample)\n",
    "elif q_start >= len(query.border_sample):\n",
    "    q_start -= len(query.border_sample)\n",
    "\n",
    "q_orig_stop = query.border_sample[q_stop]['orig_idx'] - min_slip\n",
    "q_orig_start = q_orig_stop - len(t_fine_seq)\n",
    "\n",
    "if q_orig_start < q_orig_stop:\n",
    "    q_fine_seq = {i:query.ordered_border[b] \n",
    "                  for i,b in enumerate(range(q_orig_start, q_orig_stop,))}\n",
    "else:\n",
    "    idx = [i for i in range(q_orig_start,len(query.ordered_border))]\n",
    "    idx = idx + [i for i in range(0, q_orig_stop+1)]\n",
    "    q_fine_seq = {i:query.ordered_border[b] for i,b in enumerate(idx)}\n",
    "\n",
    "target.reposition_by_border(t_fine_seq, q_fine_seq)   \n",
    "    \n",
    "    \n",
    "Q_x = [ q[1]['x'] for q in query.ordered_border.items() ]\n",
    "Q_y = [ q[1]['y'] for q in query.ordered_border.items() ]\n",
    "\n",
    "T_orig_x = [ t[1]['x'] for t in target.border.items() ]\n",
    "T_orig_y = [ t[1]['y'] for t in target.border.items() ]\n",
    "\n",
    "T_shifted_x = [t[1]['x'] for t in target.border.items() ]\n",
    "T_shifted_y = [t[1]['y'] for t in target.border.items() ]\n",
    "\n",
    "plt.figure(figsize = [15,15])\n",
    "plt.scatter( Q_x, Q_y, c = 'blue', s=16)\n",
    "plt.scatter( T_orig_x, T_orig_y, c = 'orange', s=16)\n",
    "plt.scatter( T_shifted_x, T_shifted_y, c = 'black', s=16)\n",
    "            \n",
    "query.merge(target)\n",
    "\n",
    "Q_merged_x = [ q[1]['x'] for q in query.border.items() ]\n",
    "Q_merged_y = [ q[1]['y'] for q in query.border.items() ]\n",
    "\n",
    "plt.figure(figsize = [15,15])\n",
    "plt.scatter( Q_merged_x, Q_merged_y, c = 'blue', s=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# REPEAT ABOVE\n",
    "######################### \n",
    "\n",
    "# burn this one for now\n",
    "target = target_pieces.pop(mx_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
